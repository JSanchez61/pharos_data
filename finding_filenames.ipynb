{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the IDs for receptor filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_filesnames(rtype):\n",
    "    # Read file list\n",
    "    file_list = pd.read_csv(\"all_files.csv\")\n",
    "    # Read receptor list\n",
    "    receptors = pd.read_csv(\"should_have/\" + rtype  + \".csv\")\n",
    "    receptors[\"name_fmt\"] = receptors.description.apply(lambda x: x.replace(\"-\", \"_\").replace(\" \", \"_\").replace(\n",
    "    \"'\", \"\").replace(\"/\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").lower())\n",
    "    # Create column for paths\n",
    "    receptors['path'] = np.zeros(len(receptors), dtype=str)\n",
    "    print(\"There should be:\", len(receptors))\n",
    "    # Store matches\n",
    "    locs = []\n",
    "    # Store queries\n",
    "    queries = []\n",
    "    # Search matches\n",
    "    for path in file_list.path:\n",
    "        fname = path.split(\"/\")[-1]\n",
    "        query = fname.replace(\"decoys_\", \"\").replace(\".sdf\", \"\").lower()\n",
    "        queries.append(query)\n",
    "        loc = np.where(receptors.name_fmt == query)[0]\n",
    "        # Save path\n",
    "        if len(loc > 0):\n",
    "            locs.append(loc[0])\n",
    "            receptors.path[loc[0]] = path\n",
    "    # Check that the paths are all unique.\n",
    "    for l, count in [(l, locs.count(l)) for l in locs]:\n",
    "        if count > 1:\n",
    "            print(receptors.name_fmt.iloc[l])\n",
    "    assert len(np.unique(np.array(locs))) == len(locs), \"Not all paths are unique!\"\n",
    "    print(\"All paths are unique!\")\n",
    "    print(\"Found:\", len(locs))\n",
    "    # Count missing items\n",
    "    unk = []\n",
    "    for f in receptors.name_fmt:\n",
    "        if f not in queries:\n",
    "            unk.append(f)\n",
    "    print(\"Missing:\", len(unk))\n",
    "    print(receptors.shape)\n",
    "    print(\"Saving csv.\")\n",
    "    receptors = receptors.loc[:, [\"id\", \"description\", \"name\", \"uniprot\",\n",
    "                                  \"num_actives\", \"name_fmt\", \"path\" ]]\n",
    "    receptors.to_csv(rtype + \"_paths.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "Searching for: Enzyme\n",
      "There should be: 348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ravila/Software/miniconda/lib/python3.6/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All paths are unique!\n",
      "Found: 83\n",
      "Missing: 265\n",
      "(348, 12)\n",
      "Saving csv.\n",
      "=========================\n",
      "Searching for: Epigenetic\n",
      "There should be: 42\n",
      "All paths are unique!\n",
      "Found: 30\n",
      "Missing: 12\n",
      "(42, 12)\n",
      "Saving csv.\n",
      "=========================\n",
      "Searching for: GPCR\n",
      "There should be: 189\n",
      "All paths are unique!\n",
      "Found: 172\n",
      "Missing: 17\n",
      "(189, 12)\n",
      "Saving csv.\n",
      "=========================\n",
      "Searching for: IC\n",
      "There should be: 91\n",
      "All paths are unique!\n",
      "Found: 46\n",
      "Missing: 45\n",
      "(91, 12)\n",
      "Saving csv.\n",
      "=========================\n",
      "Searching for: Kinase\n",
      "There should be: 205\n",
      "All paths are unique!\n",
      "Found: 48\n",
      "Missing: 157\n",
      "(205, 12)\n",
      "Saving csv.\n",
      "=========================\n",
      "Searching for: NR\n",
      "There should be: 28\n",
      "All paths are unique!\n",
      "Found: 24\n",
      "Missing: 4\n",
      "(28, 12)\n",
      "Saving csv.\n",
      "=========================\n",
      "Searching for: TF\n",
      "There should be: 6\n",
      "All paths are unique!\n",
      "Found: 6\n",
      "Missing: 0\n",
      "(6, 12)\n",
      "Saving csv.\n",
      "=========================\n",
      "Searching for: TF; Epigenetic\n",
      "There should be: 5\n",
      "All paths are unique!\n",
      "Found: 5\n",
      "Missing: 0\n",
      "(5, 12)\n",
      "Saving csv.\n",
      "=========================\n",
      "Searching for: Transporter\n",
      "There should be: 35\n",
      "All paths are unique!\n",
      "Found: 16\n",
      "Missing: 19\n",
      "(35, 12)\n",
      "Saving csv.\n"
     ]
    }
   ],
   "source": [
    "rnames = ['Enzyme', 'Epigenetic', 'GPCR', 'IC', 'Kinase', 'NR', 'TF', 'TF; Epigenetic', 'Transporter']\n",
    "for r in rnames:\n",
    "    print(\"=========================\")\n",
    "    print(\"Searching for:\", r)\n",
    "    get_filesnames(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
